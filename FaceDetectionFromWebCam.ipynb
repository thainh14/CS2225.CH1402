{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceDetectionFromWebCam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOafGsGWOGkKOg7XT1SSF5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuvh87/CS2225.CH1402/blob/master/FaceDetectionFromWebCam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjZIgpbz5Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/vuvh87/CS2225.CH1402.git vra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khk_z422rZvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C87p9hlo0QC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo2BIGUQvlAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ffmpeg-python\n",
        "\n",
        "\n",
        "from IPython.display import HTML, Javascript, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "video_file_train = '/content/Video/vra_train.mp4' \n",
        "video_file_test = '/content/Video/vra_test.mp4' \n",
        "  \n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var my_btn_txt = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(my_btn_txt);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, videoStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  videoStream = stream;\n",
        "  var options = {  \n",
        "    mimeType : 'video/webm;codecs=vp9'  \n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream, options);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('video');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({video: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      videoStream.getVideoTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... Please wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def start_webcam():\n",
        "  js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      \n",
        "      return;\n",
        "\n",
        "    }\n",
        "    ''')\n",
        "  \n",
        "  display(js)\n",
        "  data = eval_js('startWebcam()')\n",
        "  \n",
        "    \n",
        "start_webcam()\n",
        "\n",
        "def get_video():\n",
        "  display(HTML(VIDEO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  return binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRZD1GLSwKy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videofile = get_video()\n",
        "\n",
        "with open(video_file_train, 'wb') as f:\n",
        "  f.write(videofile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ_YxoU-wTGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "videofile = get_video()\n",
        "\n",
        "with open(video_file_test, 'wb') as f:\n",
        "  f.write(videofile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG_FzrzOwkqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2, sys, numpy, os\n",
        "from time import sleep\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# OpenCV Default config file for face detection\n",
        "haar_file = '/content/vra/haarcascades/haarcascade_frontalface_default.xml'\n",
        "  \n",
        "# Root Folder used to store the face data images\n",
        "datasets = '/content/Dataset'\n",
        " \n",
        "# Subfolder used to store my images (to be changed with your name)\n",
        "sub_data = 'Offer'     \n",
        "  \n",
        "path = os.path.join(datasets, sub_data) \n",
        "if not os.path.isdir(path): \n",
        "    os.mkdir(path) \n",
        "  \n",
        "# define the size of images  \n",
        "(width, height) = (130, 100)     \n",
        "  \n",
        "# Analyse the video training file \n",
        "face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "webcam = cv2.VideoCapture(video_file_train)  \n",
        "  \n",
        "# Capture the first 50 images of the train video\n",
        "count = 1\n",
        "while count < 50: \n",
        "    if not webcam.isOpened():\n",
        "        print('Unable to load the video file.')\n",
        "        sleep(5)\n",
        "        pass  \n",
        "    (_, im) = webcam.read() \n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 4) \n",
        "    for (x, y, w, h) in faces: \n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
        "        face = gray[y:y + h, x:x + w] \n",
        "        face_resize = cv2.resize(face, (width, height)) \n",
        "        cv2.imwrite('% s/% s.png' % (path, count), face_resize) \n",
        "    count += 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcjiOQ2s0qdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# User OpenCV Face Recognizer to train the AI & Cascade Classifier to detect faces\n",
        "  \n",
        "# Create a list of images and a list of corresponding names \n",
        "(images, lables, names, id) = ([], [], {}, 0) \n",
        "for (subdirs, dirs, files) in os.walk(datasets): \n",
        "    for subdir in dirs: \n",
        "        names[id] = subdir \n",
        "        subjectpath = os.path.join(datasets, subdir) \n",
        "        for filename in os.listdir(subjectpath): \n",
        "            path = subjectpath + '/' + filename \n",
        "            lable = id\n",
        "            images.append(cv2.imread(path, 0)) \n",
        "            lables.append(int(lable)) \n",
        "        id += 1\n",
        "(width, height) = (130, 100) \n",
        "  \n",
        "# Create a Numpy array from the two lists above \n",
        "(images, lables) = [numpy.array(lis) for lis in [images, lables]] \n",
        "  \n",
        "# Train the model from the images with OpenCV Face Recognizer\n",
        "model = cv2.face.LBPHFaceRecognizer_create()\n",
        "model.train(images, lables) \n",
        "  \n",
        "# Use OpenCV Cascade Classifier to detect faces \n",
        "face_cascade = cv2.CascadeClassifier(haar_file) \n",
        "webcam = cv2.VideoCapture(video_file_test)\n",
        "\n",
        "count = 1\n",
        "while count < 30:\n",
        "    (_, im) = webcam.read() \n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) \n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
        "    for (x, y, w, h) in faces: \n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (255, 0, 0), 2) \n",
        "        face = gray[y:y + h, x:x + w] \n",
        "        face_resize = cv2.resize(face, (width, height)) \n",
        "        # Try to recognize the face \n",
        "        prediction = model.predict(face_resize) \n",
        "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 3) \n",
        "  \n",
        "        if prediction[1]<100: \n",
        "           cv2.putText(im, '% s - %.0f' % (names[prediction[0]], prediction[1]), (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n",
        "           cv2_imshow(im)\n",
        "           break\n",
        "        else: \n",
        "          cv2.putText(im, 'not recognized', (x-10, y-10), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0)) \n",
        "  \n",
        "    count += 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGauD5hR2WtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in os.listdir('/content/Dataset/Offer'):\n",
        "  im = cv2.imread(os.path.join('/content/Dataset/Offer', filename))\n",
        "  cv2_imshow(im)\n",
        "cv2.waitKey()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
